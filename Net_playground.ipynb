{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mimg\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageColor, ImageFont, ImageDraw, ImageFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import DL stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.functional as F\n",
    "from torch.autograd import Variable as V\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import tensorflow as tf\n",
    "\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import Converter, Resize, Normalize, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf: 1.12.0 \n",
      "\r",
      " torch: 1.0.0\n"
     ]
    }
   ],
   "source": [
    "print('tf:', tf.__version__, '\\n\\r', 'torch:', torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/data.csv', sep=';', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataStream(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = pd.read_csv('./data/data.csv', sep=';', header=None)\n",
    "        self.imgs = self.data[0]\n",
    "        self.labels = self.data[1]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = io.imread(self.imgs[idx])\n",
    "        y = self.labels[idx]\n",
    "        sample = {'img' : x, 'label' : y}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = DataStream(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataStream' object is not an iterator",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-ebf5e71bd798>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'DataStream' object is not an iterator"
     ]
    }
   ],
   "source": [
    "sample = next(dr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 1, 71])\n",
      "torch.Size([71, 1, 32])\n"
     ]
    }
   ],
   "source": [
    "H = 32\n",
    "W = 280\n",
    "C = 1\n",
    "net = CRNN(C, nc=32, nh=128)\n",
    "net.apply(weights_init)\n",
    "X = V(torch.randn(1, C, H, W))\n",
    "Y_ = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = nn.CTCLoss("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16 * 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttrDict(dict):\n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "    \n",
    "def define_config():\n",
    "    config = AttrDict()\n",
    "    config.n_classes = 34\n",
    "    config.lstm_size = 256\n",
    "    config.width = 280\n",
    "    config.height = 32\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_classes': 34, 'lstm_size': 256}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.rnn import BasicLSTMCell\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "cfg = define_config()\n",
    "\n",
    "def cnn(inputs, scope='vgg', is_training=True):\n",
    "    batch_norm_params = {'is_training': is_training}\n",
    "    with slim.arg_scope([slim.conv2d], \n",
    "                        normalizer_fn=slim.batch_norm, \n",
    "                        normalizer_params=batch_norm_params,):\n",
    "        with slim.arg_scope([slim.batch_norm], **batch_norm_params):\n",
    "            net = slim.repeat(\n",
    "                inputs, 1, \n",
    "                slim.conv2d, \n",
    "                64, [3, 3], \n",
    "                scope='conv1',\n",
    "            )\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
    "            net = slim.repeat(net, 1, slim.conv2d, 128, [3, 3], scope='conv2')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool2', padding='SAME')\n",
    "            net = slim.repeat(net, 2, slim.conv2d, 256, [3, 3], scope='conv3')\n",
    "            net = slim.max_pool2d(net, [2, 2], stride=[2, 1], scope='pool3', padding='SAME')\n",
    "            net = slim.repeat(net, 2, slim.conv2d, 512, [3, 3], scope='conv4')\n",
    "            net = slim.max_pool2d(net, [2, 2], stride=[2, 1], scope='pool4', padding='SAME')\n",
    "            net = slim.repeat(net, 1, slim.conv2d, 512, [3, 3], scope='conv5')\n",
    "            return net\n",
    "\n",
    "\n",
    "def crnn(images, is_training=True):\n",
    "    dropout_keep_prob = 0.7 if is_training else 1.0\n",
    "    cnn_net = cnn(images, is_training=is_training)\n",
    "    with tf.variable_scope('Reshaping_cnn'):\n",
    "        shape = cnn_net.get_shape().as_list()  # [batch, height, width, features]\n",
    "        transposed = tf.transpose(cnn_net, perm=[0, 2, 1, 3],\n",
    "                                  name='transposed')  # [batch, width, height, features]\n",
    "        conv_reshaped = tf.reshape(transposed, [shape[0], -1, shape[1] * shape[3]],\n",
    "                                   name='reshaped')  # [batch, width, height x features]\n",
    "\n",
    "    list_n_hidden = [cfg.lstm_size, cfg.lstm_size]\n",
    "\n",
    "    with tf.name_scope('deep_bidirectional_lstm'):\n",
    "        # Forward direction cells\n",
    "        fw_cell_list = [BasicLSTMCell(nh, forget_bias=1.0) for nh in list_n_hidden]\n",
    "        # Backward direction cells\n",
    "        bw_cell_list = [BasicLSTMCell(nh, forget_bias=1.0) for nh in list_n_hidden]\n",
    "\n",
    "        lstm_net, _, _ = tf.contrib.rnn.stack_bidirectional_dynamic_rnn(fw_cell_list,\n",
    "                                                                        bw_cell_list,\n",
    "                                                                        conv_reshaped,\n",
    "                                                                        dtype=tf.float32\n",
    "                                                                        )\n",
    "        # Dropout layer\n",
    "        lstm_net = tf.nn.dropout(lstm_net, keep_prob=dropout_keep_prob)\n",
    "        #logging.info('after lstm shape: %s' % lstm_net.shape)\n",
    "\n",
    "    with tf.variable_scope('fully_connected'):\n",
    "        shape = lstm_net.get_shape().as_list()  # [batch, width, 2*n_hidden]\n",
    "        fc_out = slim.layers.linear(lstm_net, cfg.n_classes)  # [batch x width, n_class]\n",
    "        #logging.info('fc_out shape: %s' % fc_out.shape)\n",
    "\n",
    "        lstm_out = tf.reshape(fc_out, [shape[0], -1, cfg.n_classes],\n",
    "                              name='lstm_out')  # [batch, width, n_classes]\n",
    "        #logging.info('lstm_out shape: %s' % lstm_out.shape)\n",
    "\n",
    "        # Swap batch and time axis\n",
    "        logprob = tf.transpose(lstm_out, [1, 0, 2], name='transpose_time_major')  # [width(time), batch, n_classes]\n",
    "\n",
    "        return logprob\n",
    "\n",
    "\n",
    "def create_loss(sparse_code_target, logprob, seq_len_inputs):\n",
    "    with tf.control_dependencies(\n",
    "            [tf.less_equal(sparse_code_target.dense_shape[1], tf.reduce_max(tf.cast(seq_len_inputs, tf.int64)))]):\n",
    "        loss_ctc = tf.nn.ctc_loss(labels=sparse_code_target,\n",
    "                                  inputs=logprob,\n",
    "                                  sequence_length=tf.cast(seq_len_inputs, tf.int32),\n",
    "                                  ignore_longer_outputs_than_inputs=True,\n",
    "                                 )\n",
    "        loss_ctc = tf.reduce_mean(loss_ctc)\n",
    "    return loss_ctc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0211 16:57:17.981990 140354946066176 tf_logging.py:161] <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fa648325710>: Note that this cell is not optimized for performance. Please use tf.contrib.cudnn_rnn.CudnnLSTM for better performance on GPU.\n",
      "W0211 16:57:17.984064 140354946066176 tf_logging.py:161] <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fa648325940>: Note that this cell is not optimized for performance. Please use tf.contrib.cudnn_rnn.CudnnLSTM for better performance on GPU.\n",
      "W0211 16:57:17.985587 140354946066176 tf_logging.py:161] <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fa648325208>: Note that this cell is not optimized for performance. Please use tf.contrib.cudnn_rnn.CudnnLSTM for better performance on GPU.\n",
      "W0211 16:57:17.987194 140354946066176 tf_logging.py:161] <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fa6483255c0>: Note that this cell is not optimized for performance. Please use tf.contrib.cudnn_rnn.CudnnLSTM for better performance on GPU.\n"
     ]
    }
   ],
   "source": [
    "ret = crnn(np.random.rand(1,224,64,3).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(16), Dimension(1), Dimension(34)])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text):\n",
    "    if isinstance(text, str):\n",
    "        te"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
